{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzbwdmfWGVyhj2vYRgCk9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaperei/data-science/blob/main/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8xMsnwICiH"
      },
      "source": [
        "## Description\n",
        "This algorithm intends to implement a perceptron neural network from scratch, in order to solve the Iris problem\n",
        "\n",
        "### The activation functions for the 3 neurons can be defined by:\n",
        "\n",
        "```\n",
        "weights1[0]*x1 + weights2[0]*x2 + weights3[0]*x3 + weights4[0]*x4 > bias1 -> y1=1 (Iris-setosa), else y1=0\n",
        "```\n",
        "```\n",
        "weights1[1]*x1 + weights2[1]*x2 + weights3[1]*x3 + weights4[1]*x4 > bias2 -> y2=1 (Iris-versicolor), else y2=0\n",
        "```\n",
        "```\n",
        "weights1[2]*x1 + weights2[2]*x2 + weights3[2]*x3 + weights4[2]*x4 > bias3 -> y1=1 (Iris-virginica), else y3=0\n",
        "```\n",
        "\n",
        "### Trainning algorithm\n",
        "```\n",
        "w(t+1)= w(t) + learning_rate * (expected(t) - predicted(t)) * x(t)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oOp7N8Ni04h"
      },
      "source": [
        "# -------------start variables-------------#\n",
        "# define weights for each input\n",
        "# initialize weights for the 1st input\n",
        "weights1 = [0.01616566161616166, 0.12924319712744639, -0.29849152656899693]\n",
        "\n",
        "# initialize weights for the 2nd input\n",
        "weights2 = [-0.14500555908542854, 0.20653640140000007, -0.23418117710000003]\n",
        "\n",
        "# initialize weights for the 3rd input\n",
        "weights3 = [0.54026516182618454, 0.15180000000164556, -0.09207238729099955]\n",
        "\n",
        "# initialize weights for the 4th input\n",
        "weights4 = [0.19245325244444489, 0.26554984984978444, -0.02749754940654964]\n",
        "\n",
        "# define bias for each output neuron\n",
        "bias1 = 0.0\n",
        "bias2 = 0.0\n",
        "bias3 = 0.0\n",
        "# -------------end variables---------------#"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii16w8PQjQtV"
      },
      "source": [
        "# Make a prediction with weights\n",
        "def predict(row):\n",
        "\n",
        "\tactivation1 = 0.0\n",
        "\tactivation2 = 0.0\n",
        "\tactivation3 = 0.0\n",
        "\n",
        "\tweights = []\n",
        "\n",
        "\t# predict 1st output y1 - Iris-setosa\n",
        "\tweights = [weights1[0], weights2[0], weights3[0], weights4[0]]\n",
        "\tfor i in range(4):\n",
        "\t\tactivation1 += weights[i] * row[i]\n",
        "  \n",
        "\t# predict 2nd output  y2 - Iris-versicolor\n",
        "\tweights = [weights1[1], weights2[1], weights3[1], weights4[1]]\n",
        "\tfor i in range(4):\n",
        "\t\tactivation2 += weights[i] * row[i]\n",
        "\n",
        "  # predict 3rd output y3 - Iris-virginica\n",
        "\tweights = [weights1[2], weights2[2], weights3[2], weights4[2]]\n",
        "\tfor i in range(4):\n",
        "\t\tactivation3 += weights[i] * row[i]\n",
        "\t\n",
        "\tif activation1 >= bias1:\n",
        "\t\tactivation1 = 1\n",
        "\telse:\n",
        "\t\tactivation1 = 0\n",
        "\n",
        "\tif activation2 >= bias2:\n",
        "\t\tactivation2 = 1\n",
        "\telse:\n",
        "\t\tactivation2 = 0\n",
        "\n",
        "\tif activation3 >= bias3:\n",
        "\t\tactivation3 = 1\n",
        "\telse:\n",
        "\t\tactivation3 = 0\n",
        "\n",
        "\treturn [activation1, activation2, activation3]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR4N0FdijeyT"
      },
      "source": [
        "# Estimate Perceptron weights using stochastic gradient descent\n",
        "# w(t+1)= w(t) + learning_rate * (expected(t) - predicted(t)) * x(t)\n",
        "def train_weights(train, l_rate):\n",
        "\tfor row in train:\n",
        "\t\tprediction = predict(row)\n",
        "\t\terror1 = row[4] - prediction[0]\n",
        "\t\terror2 = row[5] - prediction[1]\n",
        "\t\terror3 = row[6] - prediction[2]\n",
        "\n",
        "\t\tweights1[0] = weights1[0] + l_rate * error1 * row[0]\n",
        "\t\tweights2[0] = weights2[0] + l_rate * error1 * row[1]\n",
        "\t\tweights3[0] = weights2[0] + l_rate * error1 * row[2]\n",
        "\t\tweights4[0] = weights4[0] + l_rate * error1 * row[3]\n",
        "\n",
        "\t\tweights1[1] = weights1[1] + l_rate * error2 * row[0]\n",
        "\t\tweights2[1] = weights2[1] + l_rate * error2 * row[1]\n",
        "\t\tweights3[1] = weights2[1] + l_rate * error2 * row[2]\n",
        "\t\tweights4[1] = weights4[1] + l_rate * error2 * row[3]\n",
        "\n",
        "\t\tweights1[2] = weights1[2] + l_rate * error3 * row[0]\n",
        "\t\tweights2[2] = weights2[2] + l_rate * error3 * row[1]\n",
        "\t\tweights3[2] = weights2[2] + l_rate * error3 * row[2]\n",
        "\t\tweights4[2] = weights4[2] + l_rate * error3 * row[3]\n",
        "\n",
        "\t#print('lrate=%.3f, error1=%.3f, error2=%.3f, error3=%.3f' % (l_rate, error1, error2, error3))"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1u6IN-LjsBP"
      },
      "source": [
        "def calculate_accuracy_using_test_data(test):\n",
        "\tsuccesses = 0\n",
        "\taccuracy = 0\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(row)\n",
        "\t\tprint(\"Expected=%d-%d-%d, Predicted=%d-%d-%d\" % (row[4], row[5], row[6], prediction[0], prediction[1], prediction[2]))\n",
        "\t\tif(row[4]==prediction[0] and row[5]==prediction[1] and row[6]==prediction[2]):\n",
        "\t\t\tsuccesses = successes + 1\n",
        "\t\n",
        "\taccuracy = successes/len(test)\n",
        "\n",
        "\tprint(\"Test accuracy - %.5f\", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRD6xXoDPhUp",
        "outputId": "b8850ad2-46e1-4ba3-a4e0-6e1b3dae268a"
      },
      "source": [
        "# load csv file and train the perceptron\n",
        "\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "\n",
        "# import data from csv file\n",
        "dataset = pd.read_csv('data-iris.csv', sep=',')\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "data_list = dataset.values.tolist()\n",
        "rd.shuffle(data_list)\n",
        "\n",
        "trainning = data_list[0:134] # 90% of entire list\n",
        "test = data_list[135:149] # 10% of entire list\n",
        "\n",
        "for i in range(500):\n",
        "\ttrain_weights(trainning, 0.01)\n",
        "\n",
        "calculate_accuracy_using_test_data(test)\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     input1  input2  input3  input4  output1  output2  output3\n",
            "0       5.1     3.5     1.4     0.2        1        0        0\n",
            "1       4.9     3.0     1.4     0.2        1        0        0\n",
            "2       4.7     3.2     1.3     0.2        1        0        0\n",
            "3       4.6     3.1     1.5     0.2        1        0        0\n",
            "4       5.0     3.6     1.4     0.2        1        0        0\n",
            "..      ...     ...     ...     ...      ...      ...      ...\n",
            "145     6.7     3.0     5.2     2.3        0        0        1\n",
            "146     6.3     2.5     5.0     1.9        0        0        1\n",
            "147     6.5     3.0     5.2     2.0        0        0        1\n",
            "148     6.2     3.4     5.4     2.3        0        0        1\n",
            "149     5.9     3.0     5.1     1.8        0        0        1\n",
            "\n",
            "[150 rows x 7 columns]\n",
            "Expected=0-1-0, Predicted=0-0-1\n",
            "Expected=0-1-0, Predicted=0-0-0\n",
            "Expected=0-1-0, Predicted=0-1-0\n",
            "Expected=0-1-0, Predicted=0-0-0\n",
            "Expected=1-0-0, Predicted=1-0-0\n",
            "Expected=0-1-0, Predicted=0-1-0\n",
            "Expected=0-1-0, Predicted=0-1-0\n",
            "Expected=0-1-0, Predicted=0-1-0\n",
            "Expected=0-1-0, Predicted=0-0-0\n",
            "Expected=1-0-0, Predicted=1-0-0\n",
            "Expected=0-1-0, Predicted=0-0-0\n",
            "Expected=0-0-1, Predicted=0-0-1\n",
            "Expected=0-1-0, Predicted=0-0-0\n",
            "Expected=0-0-1, Predicted=0-0-1\n",
            "Test accuracy - %.5f 57.14285714285714\n"
          ]
        }
      ]
    }
  ]
}